{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package              Version\n",
      "-------------------- -------------------\n",
      "absl-py              0.11.0\n",
      "appnope              0.1.0\n",
      "argon2-cffi          20.1.0\n",
      "astor                0.8.1\n",
      "async-generator      1.10\n",
      "attrs                20.2.0\n",
      "backcall             0.2.0\n",
      "bleach               3.2.1\n",
      "certifi              2020.6.20\n",
      "cffi                 1.14.3\n",
      "chardet              3.0.4\n",
      "decorator            4.4.2\n",
      "defusedxml           0.6.0\n",
      "entrypoints          0.3\n",
      "gast                 0.2.2\n",
      "google-pasta         0.2.0\n",
      "gpt-2-simple         0.7.1\n",
      "grpcio               1.31.0\n",
      "h5py                 2.10.0\n",
      "idna                 2.10\n",
      "importlib-metadata   2.0.0\n",
      "ipykernel            5.3.4\n",
      "ipython              7.19.0\n",
      "ipython-genutils     0.2.0\n",
      "jedi                 0.17.2\n",
      "Jinja2               2.11.2\n",
      "jsonschema           3.2.0\n",
      "jupyter-client       6.1.7\n",
      "jupyter-core         4.6.3\n",
      "jupyterlab-pygments  0.1.2\n",
      "Keras-Applications   1.0.8\n",
      "Keras-Preprocessing  1.1.0\n",
      "Markdown             3.3.2\n",
      "MarkupSafe           1.1.1\n",
      "mistune              0.8.4\n",
      "mkl-fft              1.2.0\n",
      "mkl-random           1.1.1\n",
      "mkl-service          2.3.0\n",
      "nbclient             0.5.1\n",
      "nbconvert            6.0.7\n",
      "nbformat             5.0.8\n",
      "nest-asyncio         1.4.1\n",
      "notebook             6.1.4\n",
      "numpy                1.19.2\n",
      "opt-einsum           3.1.0\n",
      "packaging            20.4\n",
      "pandocfilters        1.4.2\n",
      "parso                0.7.0\n",
      "pexpect              4.8.0\n",
      "pickleshare          0.7.5\n",
      "pip                  20.2.4\n",
      "prometheus-client    0.8.0\n",
      "prompt-toolkit       3.0.8\n",
      "protobuf             3.13.0\n",
      "ptyprocess           0.6.0\n",
      "pycparser            2.20\n",
      "Pygments             2.7.2\n",
      "pyparsing            2.4.7\n",
      "pyrsistent           0.17.3\n",
      "python-dateutil      2.8.1\n",
      "pyzmq                19.0.2\n",
      "regex                2020.10.28\n",
      "requests             2.24.0\n",
      "scipy                1.5.2\n",
      "Send2Trash           1.5.0\n",
      "setuptools           50.3.0.post20201103\n",
      "six                  1.15.0\n",
      "tensorboard          1.15.0\n",
      "tensorflow           1.15.0\n",
      "tensorflow-estimator 1.15.1\n",
      "termcolor            1.1.0\n",
      "terminado            0.9.1\n",
      "testpath             0.4.4\n",
      "toposort             1.5\n",
      "tornado              6.0.4\n",
      "tqdm                 4.51.0\n",
      "traitlets            5.0.5\n",
      "urllib3              1.25.11\n",
      "wcwidth              0.2.5\n",
      "webencodings         0.5.1\n",
      "Werkzeug             0.16.1\n",
      "wheel                0.35.1\n",
      "wrapt                1.12.1\n",
      "zipp                 3.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate text locally with GPT2 Simple\n",
    "\n",
    "This tutorial assumes that you have trained/fine-tuned a new language model in our Google Colab example. Additionally, you should have created a new Anaconda environment (in this case called nlp) with Tensor Flow 1.15 and gpt-2-spimple installed.\n",
    "\n",
    "<br>\n",
    "You can disregard the TF2.0 warnings that will result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following cell is required to prevent an annoying duplicate library error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import re\n",
    "from subprocess import Popen, PIPE\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is not required, but good to confirm that your python environment has properly installed `gpt-2-simple 0.7.1` and `tensorflow 1.15.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this notebook is located in your new project folder `gpt2`, you will not need to change directories. Here we Print Working Directory `pwd` to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ben/Dev/gpt2'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not in the correct directory that contains your checkpoint folder, you can use `os.chdir()` to navigate to the proper dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = '/Users/ben/Dev/gpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(workdir) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have unzipped the .tar archive generated during the fine-tuning process. In this example, the checkpoint directory is `.../gpt2/checkpoint/ghandi` Regardless, the `run_name` should correspond with the folder name *inside* of 'checkpoint.' So you may need to change `run_name` to `'run1'` \n",
    "\n",
    "<br> \n",
    "Starting this TF session will take a minute or so, then you should get feedback that the chackpoint has been loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_text(prompt, run, sess):\n",
    "    text = gpt2.generate(sess,\n",
    "                        run_name=run,\n",
    "                        length=30,\n",
    "                        temperature=0.7,\n",
    "                        prefix=prompt,\n",
    "                        nsamples=1,\n",
    "                        batch_size=1,\n",
    "                        return_as_list=True\n",
    "                        )\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    stop = re.compile(\"\\.\")\n",
    "    comma = re.compile(\",\")\n",
    "    num_stops = len(stop.findall(text))\n",
    "    if num_stops >= 2:\n",
    "        return text.split(\".\")\n",
    "    num_commas = len(comma.findall(text))\n",
    "    if num_commas >= 2:\n",
    "        return text.split(\",\")\n",
    "    words = text.split()\n",
    "    middle = int(len(words)/2)\n",
    "    rtn = list([\" \".join(words[:middle]), \" \".join(words[middle:])])\n",
    "    return rtn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_popen(prompt, run):\n",
    "    cmd = workdir + \"/gpt_2_simple generate --run_name \" + run\n",
    "    cmd += \" --length 30 --temperature 0.7 --prefix \\\"\" + prompt + \"\\\"\"\n",
    "    cmd += \" --nsamples 1 --batch_size 1\"\n",
    "    p = Popen(cmd, stdout=PIPE, stderr=PIPE, shell=True)\n",
    "    (out, err) = p.communicate()\n",
    "    if p.returncode != 0:\n",
    "        print(out)\n",
    "        print(err)\n",
    "        print(\"ERROR!\")\n",
    "        \n",
    "        return False\n",
    "    gendir = os.path.join(workdir, \"gen\")\n",
    "    list_of_files = glob.glob('{0}/gen/*'.format(workdir))\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    fcontents = open(latest_file).read()\n",
    "    os.unlink(latest_file)\n",
    "    rtn = split_text(fcontents)\n",
    "    return rtn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def say_it(phrase):\n",
    "    cmd = \"say \" + phrase\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = gpt2.start_tf_sess()\n",
    "# gpt2.load_gpt2(sess, run_name='guardian1')\n",
    "# gpt2.load_gpt2(sess, run_name='goldman1')\n",
    "# this doesn't work because tensorflow won't allow two thingies at once\n",
    "# needs a separate interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a new string that will be the prompt for GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'A protest is a'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok now it's just my stuff I guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ben/Dev/gpt2/gpt_2_simple generate --run_name guardian1 --length 30 --temperature 0.7 --prefix \"A protest is a\" --nsamples 1 --batch_size 1\n",
      "/Users/ben/Dev/gpt2/gpt_2_simple generate --run_name goldman1 --length 30 --temperature 0.7 --prefix \"A protest is a\" --nsamples 1 --batch_size 1\n",
      "/Users/ben/Dev/gpt2/gpt_2_simple generate --run_name guardian1 --length 30 --temperature 0.7 --prefix \"I went to see\" --nsamples 1 --batch_size 1\n",
      "/Users/ben/Dev/gpt2/gpt_2_simple generate --run_name goldman1 --length 30 --temperature 0.7 --prefix \"I went to see\" --nsamples 1 --batch_size 1\n",
      "/Users/ben/Dev/gpt2/gpt_2_simple generate --run_name guardian1 --length 30 --temperature 0.7 --prefix \"could have foreseen the\" --nsamples 1 --batch_size 1\n",
      "/Users/ben/Dev/gpt2/gpt_2_simple generate --run_name goldman1 --length 30 --temperature 0.7 --prefix \"could have foreseen the\" --nsamples 1 --batch_size 1\n",
      "/Users/ben/Dev/gpt2/gpt_2_simple generate --run_name guardian1 --length 30 --temperature 0.7 --prefix \"But I was not\" --nsamples 1 --batch_size 1\n",
      "/Users/ben/Dev/gpt2/gpt_2_simple generate --run_name goldman1 --length 30 --temperature 0.7 --prefix \"But I was not\" --nsamples 1 --batch_size 1\n",
      "/Users/ben/Dev/gpt2/gpt_2_simple generate --run_name guardian1 --length 30 --temperature 0.7 --prefix \"Its lust for blood,\" --nsamples 1 --batch_size 1\n",
      "/Users/ben/Dev/gpt2/gpt_2_simple generate --run_name goldman1 --length 30 --temperature 0.7 --prefix \"Its lust for blood\" --nsamples 1 --batch_size 1\n"
     ]
    }
   ],
   "source": [
    "turns = 5\n",
    "for i in range(turns):\n",
    "    text = gpt_popen(prompt, \"guardian1\")\n",
    "    sentence = text[0]\n",
    "    say_it(sentence)\n",
    "    print(f'Guardian: \"{sentence}\"')\n",
    "    four_words = \" \".join(sentence.split()[0:4])\n",
    "    prompt = four_words\n",
    "    \n",
    "    text = gpt_popen(prompt, \"goldman1\")\n",
    "    sentence = text[1]\n",
    "    say_it(sentence)\n",
    "    print(f'Goldman: \"{sentence}\"')\n",
    "    four_words = \" \".join(sentence.split()[0:4])\n",
    "    prompt = four_words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
